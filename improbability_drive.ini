# N2NHU Infinite Improbability Drive Configuration
# ===================================================
# Controls LLM and image provider chains.
# Providers are tried in order â€” first available wins.
#
# N2NHU Labs for Applied Artificial Intelligence

[improbability_drive]
# LLM provider order (comma separated)
# choices: gpt4all, claude, huggingface, template
llm_providers = gpt4all, claude, huggingface, template

# Image mode
# realtime = generate via SD during play (requires GPU)
# static   = pre-generated at world creation time (works anywhere)
# none     = text only
image_mode = static

[gpt4all]
enabled = true
host = localhost
port = 4891
# Model name must match exactly what GPT4All shows
# From your localhost:4891/v1/models:
#   Llama 3 8B Instruct         (best quality)
#   Llama 3.2 3B Instruct       (faster)
#   Llama 3.1 8B Instruct 128k  (long context)
#   Mistral Instruct            (good alternative)
#   Phi-3 Mini Instruct         (fastest)
model = Llama 3 8B Instruct
timeout = 60

[claude_api]
enabled = false
# Get your key at console.anthropic.com
api_key =
# claude-haiku-4-5-20251001 = fastest, cheapest
# claude-sonnet-4-6          = best quality
model = claude-haiku-4-5-20251001
max_tokens = 500

[huggingface]
enabled = false
# Get your key at huggingface.co/settings/tokens
api_key =
# LLM model for text descriptions
llm_model = meta-llama/Meta-Llama-3-8B-Instruct
# Image model for SD fallback
image_model = stabilityai/stable-diffusion-2-1

[stable_diffusion]
host = 127.0.0.1
port = 7860
timeout = 120
